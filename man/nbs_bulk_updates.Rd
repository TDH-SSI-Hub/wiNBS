% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nbs_bulk_functions.R
\name{nbs_bulk_updates}
\alias{nbs_bulk_updates}
\title{Perform updates to investigations using a data file and template of changes}
\usage{
nbs_bulk_updates(
  data,
  algorithm = NA,
  metadata = NA,
  username = NA,
  environment = "NBS Production",
  cancel_open = F,
  id_col = NA,
  uid_col = NA,
  log_file = NA,
  log_every = 100,
  message_vars = c("status", "mismatches", "time")
)
}
\arguments{
\item{data}{String/data.frame. The name a csv or the data.frame itself. Must contain an investigation local ID column.}

\item{algorithm}{String/data.frame. The name a csv or the data.frame itself which conforms to the format returned by nbs_bulk_template().}

\item{metadata}{NA/String/data.frame. A string acceptable to nbs_page_metadata_get() or a metadata data.frame. If NA, the metadata will be pulled for each investigation upon page loading (slower, but allows for changes to multiple condition types).}

\item{username}{String. The username to be used to log  into NBS initially and if an error is encountered.}

\item{cancel_open}{T/F. Should edits not be submitted if the case is open?}

\item{id_col}{String/NA. The name of the column to use for the investigation local ID. Will attempt to autodetect if NA.}

\item{uid_col}{String/NA. (Optional) The name of the column to use for the investigation uid. If present, nbs_investigation_go_to() will behave slightly differently which may help searches complete on some machines.}

\item{log_file}{String/NA. Name for the output csv. If NA, no csv will be generated.}

\item{log_every}{Numeric. Number of rows after which a log file is generated and a summary is printed.}

\item{message_vars}{Character vector. Columns to print after a row is processed. Should be columns from data, or columns created during processing (see output for examples).}

\item{envirnoment}{String. The NBS environment to log into. Should be "NBS Production" or "NBS Staging" typically.}
}
\value{
data.frame
}
\description{
This function brings together many elements of scripts used to update investigations.
A processing algorithm csv/dataframe is used to make changes to investigations found in each row of the data csv.
This function handles pre and post checks of data, error handling and re-login, time monitoring, summary printing, and process logging.
You can also choose to not submit open investigations, and not overwrite existing data.
}
